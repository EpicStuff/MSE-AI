{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from epicstuff import Dict\n",
    "from taml import taml\n",
    "\n",
    "from langchain_community.vectorstores.azuresearch import AzureSearch\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stuff like api keys\n",
    "env = Dict(taml.load('env.taml'))\n",
    "env.ai_api_ver = '2024-02-01'\n",
    "env.ai_model = 'text-embedding-ada-002'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pdf to txt\n",
    "def pdf_to_text(pdf_path):\n",
    "\tfrom PyPDF2 import PdfReader\n",
    "\treader = PdfReader(pdf_path)\n",
    "\ttext = ''\n",
    "\tfor page in reader.pages:\n",
    "\t\ttext += page.extract_text()\n",
    "\treturn text\n",
    "\n",
    "def convert_pdfs_in_folder(pdf_folder, output_folder):\n",
    "\t# Ensure the output folder exists\n",
    "\tos.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "\t# Loop through all files in the directory\n",
    "\tfor filename in os.listdir(pdf_folder):\n",
    "\t\tif filename.endswith(\".pdf\"):\n",
    "\t\t\tpdf_path = os.path.join(pdf_folder, filename)\n",
    "\t\t\ttext = pdf_to_text(pdf_path)\n",
    "\n",
    "\t\t\tif text:  # If text was extracted\n",
    "\t\t\t\t# Create a text file with the same name as the PDF\n",
    "\t\t\t\toutput_filename = os.path.splitext(filename)[0] + \".txt\"\n",
    "\t\t\t\toutput_path = os.path.join(output_folder, output_filename)\n",
    "\n",
    "\t\t\t\t# Save the extracted text to the file\n",
    "\t\t\t\twith open(output_path, \"w\", encoding=\"utf-8\") as text_file:\n",
    "\t\t\t\t\ttext_file.write(text)\n",
    "\t\t\t\tprint(f\"Converted {filename} to {output_filename}\")\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(f\"No text found in {filename}\")\n",
    "\n",
    "\n",
    "pdf_folder = \"pdfs/2023-2024 research articles\"  # Folder containing PDFs\n",
    "output_folder = \"Final/texts\"  # Folder to save text files\n",
    "\n",
    "convert_pdfs_in_folder(pdf_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# azure search object from azuresearch.ipynb\n",
    "\n",
    "from azure.search.documents.indexes.models import FreshnessScoringFunction, FreshnessScoringParameters, ScoringProfile, SearchableField, SearchField, SearchFieldDataType, \\\n",
    "\tSimpleField, TextWeights\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "\tazure_deployment=env.ai_model,\n",
    "\topenai_api_version=env.ai_api_ver,\n",
    "\tazure_endpoint=env.ai_endpoint,\n",
    "\tapi_key=env.ai_api,\n",
    ")\n",
    "embedding_function = embeddings.embed_query\n",
    "\n",
    "fields = [\n",
    "\tSimpleField(\n",
    "\t\tname='id',\n",
    "\t\ttype=SearchFieldDataType.String,\n",
    "\t\tkey=True,\n",
    "\t\tfilterable=True,\n",
    "\t),\n",
    "\tSearchableField(\n",
    "\t\tname='content',\n",
    "\t\ttype=SearchFieldDataType.String,\n",
    "\t\tsearchable=True,\n",
    "\t),\n",
    "\tSearchField(\n",
    "\t\tname='content_vector',\n",
    "\t\ttype=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "\t\tsearchable=True,\n",
    "\t\tvector_search_dimensions=len(embedding_function('Text')),\n",
    "\t\tvector_search_profile_name='myHnswProfile',\n",
    "\t),\n",
    "\tSearchableField(\n",
    "\t\tname='metadata',\n",
    "\t\ttype=SearchFieldDataType.String,\n",
    "\t\tsearchable=True,\n",
    "\t),\n",
    "\t# Additional field to store the title\n",
    "\tSearchableField(\n",
    "\t\tname='title',\n",
    "\t\ttype=SearchFieldDataType.String,\n",
    "\t\tsearchable=True,\n",
    "\t),\n",
    "\t# Additional field for filtering on document source\n",
    "\tSimpleField(\n",
    "\t\tname='source',\n",
    "\t\ttype=SearchFieldDataType.String,\n",
    "\t\tfilterable=True,\n",
    "\t),\n",
    "\t# Additional data field for last doc update\n",
    "\tSimpleField(\n",
    "\t\tname='last_update',\n",
    "\t\ttype=SearchFieldDataType.DateTimeOffset,\n",
    "\t\tsearchable=True,\n",
    "\t\tfilterable=True,\n",
    "\t),\n",
    "]\n",
    "# Adding a custom scoring profile with a freshness function\n",
    "sc_name = 'scoring_profile'\n",
    "sc = ScoringProfile(\n",
    "\tname=sc_name,\n",
    "\ttext_weights=TextWeights(weights={'title': 5}),\n",
    "\tfunction_aggregation='sum',\n",
    "\tfunctions=[\n",
    "\t\tFreshnessScoringFunction(\n",
    "\t\t\tfield_name='last_update',\n",
    "\t\t\tboost=100,\n",
    "\t\t\tparameters=FreshnessScoringParameters(boosting_duration='P2D'),\n",
    "\t\t\tinterpolation='linear',\n",
    "\t\t)\n",
    "\t],\n",
    ")\n",
    "\n",
    "vector_store: AzureSearch = AzureSearch(\n",
    "\tazure_search_endpoint=env.search_endpoint,\n",
    "\tazure_search_key=env.search_api,\n",
    "\tindex_name='langchain-vector-demo-custom-scoring-profile',\n",
    "\tembedding_function=embeddings.embed_query,\n",
    "\tfields=fields,\n",
    "\tscoring_profiles=[sc],\n",
    "\tdefault_scoring_profile=sc_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "doc_list = []\n",
    "# load each text document into azure search\n",
    "for file in glob(f'{output_folder}/*.txt'):\n",
    "\n",
    "\tloader = TextLoader(file, encoding=\"utf-8\")\n",
    "\n",
    "\tdocuments = loader.load()\n",
    "\ttext_splitter = CharacterTextSplitter(chunk_size=700, chunk_overlap=50, separator='.')\n",
    "\tdocs = text_splitter.split_documents(documents)\n",
    "\tdoc_list.append(docs)\n",
    "\tprint(docs)\n",
    "\tprint(len(docs))   #how many chunks are there in each pdf\n",
    "\t#vector_store.add_documents(documents=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in doc_list[14]:   #see how the doc is splitted\n",
    "    print(doc.page_content)\n",
    "    print('-----------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Cohere\n",
    "from langchain_core.prompts  import PromptTemplate\n",
    "#from langchain_cohere import Cohere\n",
    "\n",
    "cohere_llm = Cohere(model=\"command\",\n",
    "                    temperature=0.1,\n",
    "                    cohere_api_key = \"xEVt3zKBQ7aPsG05ZM7EwlCdMnhZLZwfR2s7T0tu\")\n",
    "\n",
    "prompt_template = \"\"\"Answer the question with the provided context.\" \\n\\n\n",
    "                Context: \\n {context}?\\n\n",
    "                Question: \\n {question} \\n\n",
    "                Answer:\"\"\"\n",
    "\n",
    "\n",
    "prompt = PromptTemplate.from_template(template=prompt_template)\n",
    "\n",
    "# Formatting the docs for the RAG chain\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find embending \"group\" with greatest similarity to query\n",
    "#vector_store.similarity_search(query=\"How can the degree of autonomy of SDL be broken down into different levels?\", k=3, search_type=\"similarity\")[0].page_content\n",
    "vector_store.similarity_search(query=\"What are the main challenges in the translation of protocols of self-driving labs?\", k=3, search_type=\"similarity\")[1].page_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1 = 'Alhpa flow is a self driving lab system. What learning method does the system use?'\n",
    "multi_choice1 = 'A. Active learning, B. Unsupervised learning, C. Reinforcement learning, D. English learning'  #correct answer is C\n",
    "question2 = 'sciclops is used in one of the self driving lab systems. What is sciclops?'\n",
    "multi_choice2 = 'A. a robotic arm, B. a microchip, C. a software, D. a microscope'    #correct answer is A\n",
    "question3 = 'BMLP enables rapid optimisation of metabolic models and offers a realistic approach to a self-driving lab for microbial engineering. What does BMLP stand for?'\n",
    "multi_choice3 = 'A. Bayesian Metabolic Learning Platform, B. Bayesian Metabolic Learning Process, C. Boolean Matrix Logic Programming , D. Bayesian Matrix Learning Protocol'  #correct answer is C\n",
    "question4 = 'In the Adam system, what is recommended form King et al.?'\n",
    "multi_choice4 = 'A. routine supervision, B. more advanced hardware, C. complete autonomous lab, D. manual operation'   #correct answer is A\n",
    "question5 = 'BRAD is a state-of-the-art chatbot and agentic system that integrates a suite of tools to handle bioinformatics tasks. What does BRAD stand for?'\n",
    "multi_choice5 = 'A. Bioinformatics Research and Development, B.  Bioinformatics Retrieval Augmented Data, ssC. Bayesian Rapid Automated Discovery, D. Bioinformatics Rapid Automated Discovery'  #correct answer is B\n",
    "question6 = 'What scale is the chemical space of all possible molecules is often estimated at?'\n",
    "multi_choice6 = 'A. 10^40, B. 10^50, C. 10^60, D. 10^70'  #correct answer is C\n",
    "question7 = 'In the paper, GPC quantifies alterations in the hydrodynamic radius associated with molecular weight. What does GPC stand for?'\n",
    "multi_choice7 = 'A. Gel Permeation Chromatography, B. Gel Permeation Coefficient, C. Gas Permeation Constant, D. Gas Permeation Chromatography'  #correct answer is D\n",
    "question8 = 'What are the main challenges in the translation of protocols of self-driving labs?'\n",
    "multi_choice8 = 'A. data, hardware, and software; B. language, syntax, and semantics; C. data, autonomy, and execution; D. syntax, semantics, and execution'  #correct answer is D\n",
    "question9 = 'In the study that uses social networking services to operate scanning probe microscopy measurement systems, when user message is judged as not executable, how does the system respond?'\n",
    "multi_choice9 = 'A. the system does not respond; B. the system still tries to execute the command; C. the system prints none and give the reason; D. the system will pause for manual operation'  #correct answer is C\n",
    "question10 = 'The concept of SDLs has its roots in the broader field of laboratory automation, began in:'\n",
    "multi_choice10 = 'A. mid-19th century, B. early-20th century, C. mid-20th century, D. in 21st century'  #correct answer is C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG Chain\n",
    "def generate_answer(question, multi_choice):    #question and the multiple choice are separated, and only the question is used to search for the context.\n",
    "    question_template = '\\n Only one answer is correct. Only print out the one answer and the one letter (A,B,C,D) that represents it, and nothing else.'\n",
    "    llm = cohere_llm\n",
    "    docs = format_docs(vector_store.similarity_search(query=question, k=4, search_type=\"similarity\"))\n",
    "    #docs = vector_store.similarity_search(query=question, k=3, search_type=\"similarity\")[1]\n",
    "    context = docs.replace('\\x00', '')  #remove mail characters as processing of the text\n",
    "\n",
    "    #print(prompt.format(context = context, question = question + multi_choice))\n",
    "    question = question + multi_choice + question_template\n",
    "\n",
    "    #allow prompt truncation\n",
    "    return llm(prompt.format(context = context, question = question), truncate = 'START')\n",
    "\n",
    "\n",
    "def without_rag(question):\n",
    "    question_template = 'Only one answer is correct, only print out the one answer and the one letter (A,B,C,D) that represents it.'\n",
    "    question = question + question_template\n",
    "    llm = cohere_llm\n",
    "    return llm(question, truncate = 'START')\n",
    "\n",
    "n=1\n",
    "\n",
    "for question, multi_choice in zip([question1, question2, question3, question4, question5, question6, question7, question8, question9, question10],\n",
    "                                   [multi_choice1, multi_choice2, multi_choice3, multi_choice4, multi_choice5, multi_choice6, multi_choice7, multi_choice8, multi_choice9, multi_choice10]):\n",
    "    print (n)\n",
    "    print(generate_answer(question, multi_choice))\n",
    "    print('------------------')\n",
    "    print(without_rag(question+multi_choice))\n",
    "    print('==================')\n",
    "    n += 1\n",
    "\n",
    "\n",
    "\n",
    "# question = question8\n",
    "# multi_choice = multi_choice8\n",
    "\n",
    "# print(generate_answer(question, multi_choice))\n",
    "# print('------------------')\n",
    "# print(without_rag(question+multi_choice))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM with and without RAG are tested with the 10 questions, repeated for 5 times. LLM-RAG scores 9/10 for 4 times and 8/10 for 1 time. LLM without RAG scores 3/10 for 5 times."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
