{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG using Cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cohere in c:\\users\\chayan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (4.57)\n",
      "Requirement already satisfied: aiohttp<4.0,>=3.0 in c:\\users\\chayan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from cohere) (3.11.11)\n",
      "Requirement already satisfied: backoff<3.0,>=2.0 in c:\\users\\chayan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from cohere) (2.2.1)\n",
      "Requirement already satisfied: fastavro<2.0,>=1.8 in c:\\users\\chayan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from cohere) (1.10.0)\n",
      "Requirement already satisfied: importlib_metadata<7.0,>=6.0 in c:\\users\\chayan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from cohere) (6.11.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.25.0 in c:\\users\\chayan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from cohere) (2.32.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\chayan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from cohere) (2.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\chayan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp<4.0,>=3.0->cohere) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\chayan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\chayan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp<4.0,>=3.0->cohere) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\chayan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp<4.0,>=3.0->cohere) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\chayan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp<4.0,>=3.0->cohere) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\chayan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp<4.0,>=3.0->cohere) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\chayan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp<4.0,>=3.0->cohere) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\chayan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp<4.0,>=3.0->cohere) (1.18.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\chayan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chayan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.25.0->cohere) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chayan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.25.0->cohere) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chayan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3.0.0,>=2.25.0->cohere) (2023.11.17)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\chayan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from multidict<7.0,>=4.5->aiohttp<4.0,>=3.0->cohere) (4.12.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install cohere\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF in c:\\users\\chayan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.25.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyMuPDF\n",
    "\n",
    "import fitz  # PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stuff like api keys\n",
    "from helpers import Dict\n",
    "from taml import taml\n",
    "# load stuff like api keys\n",
    "env = Dict(taml.load('env.taml'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach-2 Tiered Knowledge space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain Meta Data from Zotero JSON file and Obtain Publication Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year(issued):\n",
    "    \"\"\"Extracts only the year from Zotero's issued date format.\"\"\"\n",
    "    if \"date-parts\" in issued and isinstance(issued[\"date-parts\"], list):\n",
    "        date_parts = issued[\"date-parts\"][0]  # Extract first date-parts entry\n",
    "        if len(date_parts) >= 1:\n",
    "            return str(date_parts[0])  # Return only the year\n",
    "    return \"Unknown Year\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 24 journal articles from Zotero.\n"
     ]
    }
   ],
   "source": [
    "# get meta data from json file of Zotero\n",
    "\n",
    "import json\n",
    "\n",
    "# Load Zotero JSON export file\n",
    "with open(\"Research Papers.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    zotero_data = json.load(f)\n",
    "\n",
    "# Extract relevant metadata fields\n",
    "zotero_metadata = []\n",
    "for item in zotero_data:\n",
    "        metadata = {\n",
    "            \"title\": item.get(\"title\", \"Unknown Title\"),\n",
    "            \"abstract\": item.get(\"abstract\", \"Unknown Abstract\"),\n",
    "            \"DOI\": item.get(\"DOI\", \"Unknown Source\"),\n",
    "            \"year\": extract_year(item.get(\"issued\", {})),\n",
    "        }\n",
    "        zotero_metadata.append(metadata)    \n",
    "\n",
    "print(f\"Extracted {len(zotero_metadata)} journal articles from Zotero.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring profile with ReRank Relevance, Citations and year of publication\n",
    "\n",
    "Retrieved Contexts are ranked using scoring profile where Rerank Relevance is 70 % weightage. 20 % to number of citation and 10 percent for the year of publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Citation counts added to research papers.\n"
     ]
    }
   ],
   "source": [
    "# obtain number of citations for a research paper\n",
    "import re\n",
    "import requests\n",
    "\n",
    "def extract_arxiv_id(arxiv_number):\n",
    "    \"\"\"Extracts the numeric ArXiv ID from Zotero metadata.\"\"\"\n",
    "    match = re.search(r\"arXiv:(\\d+\\.\\d+)\", arxiv_number)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "def get_citation_count(doi):\n",
    "    \"\"\"Fetches citation count using OpenCitations API if DOI is available.\"\"\"\n",
    "    if not doi:\n",
    "        return 0  # If no DOI, return 0\n",
    "    base_url = f\"https://opencitations.net/index/coci/api/v1/citations/{doi}\"\n",
    "    response = requests.get(base_url)\n",
    "    if response.status_code == 200:\n",
    "        return len(response.json())  # Number of citing papers\n",
    "    return 0\n",
    "\n",
    "def get_arxiv_citations(arxiv_number):\n",
    "    \"\"\"Fetches citation count for an ArXiv paper using Semantic Scholar API.\"\"\"\n",
    "    arxiv_id = extract_arxiv_id(arxiv_number)\n",
    "    if not arxiv_id:\n",
    "        return 0  # Return 0 if extraction fails\n",
    "\n",
    "    base_url = f\"https://api.semanticscholar.org/v1/paper/arXiv:{arxiv_id}\"\n",
    "    response = requests.get(base_url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json().get(\"citationCount\", 0)  # Extract citation count\n",
    "    return 0  # Return 0 if API fails\n",
    "\n",
    "\n",
    "def enrich_paper_with_citations(paper):\n",
    "    \"\"\"Adds citation count to a paper by checking DOI or ArXiv ID.\"\"\"\n",
    "    if 'number' in paper:\n",
    "        paper['arxiv_number'] = extract_arxiv_id(paper.get('number', ''))\n",
    "        paper['citations'] = get_arxiv_citations(paper['arxiv_number'])\n",
    "    elif \"DOI\" in paper:\n",
    "        paper[\"citations\"] = get_citation_count(paper[\"DOI\"])\n",
    "    else:\n",
    "        paper[\"citations\"] = 0  # Default if no identifier found\n",
    "    return paper\n",
    "\n",
    "# Apply citation retrieval to all papers in Zotero metadata\n",
    "for paper in zotero_metadata:\n",
    "    enrich_paper_with_citations(paper)\n",
    "\n",
    "\n",
    "\n",
    "print(\" Citation counts added to research papers.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup of rerank function for retreival of research papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "# Rerank papers wrt user query \n",
    "def rerank_with_cohere(query, papers, top_n=20):\n",
    "    \"\"\"Ranks research papers using Cohere Rerank.\"\"\"\n",
    "    rerank_inputs = [f\"Title: {paper['title']} Abstract: {paper['abstract']}\" for paper in papers]\n",
    "    rerank_response = co.rerank(model=\"rerank-english-v2.0\", query=query, documents=rerank_inputs, top_n=top_n)\n",
    "    reranked_papers = [papers[result.index] for result in rerank_response.results]\n",
    "    \n",
    "    # Attach rerank scores to papers\n",
    "    for i, paper in enumerate(reranked_papers):\n",
    "        paper[\"rerank_score\"] = rerank_response.results[i].relevance_score\n",
    "    \n",
    "    return reranked_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciton for research paper scoring profile \n",
    "import datetime\n",
    "\n",
    "# Initialize Cohere API\n",
    "co = cohere.Client(env.cohere_key_trial)\n",
    "\n",
    "def apply_scoring_profile(papers, weight_rerank=0.7, weight_citations=0.2, weight_year=0.1):\n",
    "    \"\"\"Applies a scoring profile to research papers.\"\"\"\n",
    "    current_year = datetime.datetime.now().year  # Get the current year\n",
    "    scored_papers = []\n",
    "    for paper in papers:\n",
    "        citations = int(paper.get(\"citations\", 0))\n",
    "        rerank_score = float(paper.get(\"rerank_score\", 0))\n",
    "        year = int(paper.get(\"year\", 2000))  # Default to 2000 if missing\n",
    "\n",
    "        # Normalize Year Score (latest year = higher score)\n",
    "        year_score = (year - 2000) / (current_year - 2000)  # Normalized between 0 and 1\n",
    "\n",
    "        # Normalize scores\n",
    "        citation_score = min(citations / 1000, 1)  # Normalize citations (cap at 1)\n",
    "\n",
    "        # Final Score\n",
    "        final_score = (rerank_score * weight_rerank) + (citation_score * weight_citations) + (year_score * weight_year)\n",
    "\n",
    "        # Store score\n",
    "        scored_papers.append((paper, final_score))\n",
    "\n",
    "    # Sort by highest score\n",
    "    scored_papers.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return [paper for paper, score in scored_papers]\n",
    "\n",
    "def execute_ranking_pipeline(query, papers, top_n=3):\n",
    "    \"\"\"Executes full research paper ranking pipeline.\"\"\"\n",
    "    \n",
    "    # Step 1: Rerank using Cohere\n",
    "    reranked_papers = rerank_with_cohere(query, papers, top_n=5)\n",
    "    # print(reranked_papers)\n",
    "    \n",
    "    # # Step 2: Fetch citations (DOI & ArXiv support)\n",
    "    # for paper in reranked_papers:\n",
    "    #     if \"DOI\" in paper:\n",
    "    #         paper[\"citations\"] = get_citation_count(paper[\"DOI\"])\n",
    "    #     elif \"arxiv_id\" in paper:\n",
    "    #         paper[\"citations\"] = get_arxiv_citations(paper[\"arxiv_id\"])\n",
    "    #     else:\n",
    "    #         paper[\"citations\"] = 0  # Default if no identifier\n",
    "\n",
    "    # Step 3: Apply scoring profile (Relevance 0.7, Citations 0.2, Publicatio Year 0.1)\n",
    "    final_ranked_papers = apply_scoring_profile(reranked_papers)\n",
    "\n",
    "    # Return Top N Papers\n",
    "    return final_ranked_papers[:top_n]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The future of self-driving laboratories from human in the loop interactive AI to gamification (Year: 2024, Citations: 0)\n",
      " Navigation maps of the material space for automated self driving labs of the future (Year: 2024, Citations: 0)\n",
      " Autonomous Chemical Experiments Challenges and Perspectives on Establishing a Self Driving Lab (Year: 2022, Citations: 37)\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "query = \"what is the future in self driving lab\"\n",
    "top_papers = execute_ranking_pipeline(query, zotero_metadata, top_n=3)\n",
    "\n",
    "# Print final ranked results\n",
    "for paper in top_papers:\n",
    "    print(f\" {paper['title']} (Year: {paper.get('year', 'Unknown')}, Citations: {paper['citations']})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phase 2 Here we get the relevant context form the reranked research paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Create function Chunks from PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Chunk 1 ===\n",
      "Article ChemOS 2.0: An orchestration architecture for chemical self-driving laboratories ChemOS 2.0 is a comprehensive laboratory architecture for transforming the modern chemistry lab into one that accelerates the pace of chemical research. This new kind of laboratory, known as a self-driving lab (SDL), uses automated experimental tools, as well as computational experiment planners, to create fully automated workﬂows that require minimal human intervention. ChemOS 2.0 presents a modular and versatile approach to building one’s own SDL, including real-life implementations of this framework. Malcolm Sim, Mohammad Ghazi Vakili, Felix Strieth-Kalthoff, ..., Santiago Miret, Sergio Pablo-Garcı´a, Ala´n Aspuru-Guzik spgarcica@gmail.com (S.P.-G.) alan@aspuru.com (A.A.-G.) Highlights A modular strategy for building a self-driving lab for chemical research Demonstrative workﬂows based on real-world research in materials discovery High- and low-level implementation of laboratory hardware/software Automated experiment planning and execution as well as automated data collection Sim et al., Matter 7, 2959–2977 September 4, 2024 ª 2024 Elsevier Inc. All rights reserved. https://doi.org/10.1016/j.matt.2024.04.022 ll Article ChemOS 2.0: An orchestration architecture for chemical self-driving laboratories Malcolm Sim,1,2 Mohammad Ghazi Vakili,1,2 Felix Strieth-Kalthoff,1,2 Han Hao,1,2 Riley J. Hickman,1,2,3 Santiago Miret,4 Sergio Pablo-Garcı´a,1,2,3,9,* and Ala´n Aspuru-Guzik1,2,3,5,6,7,8,* \n",
      "\n",
      "=== Chunk 2 ===\n",
      "(A.A.-G.) https://doi.org/10.1016/j.matt.2024.04.022 ll 2960 Matter 7, 2959–2977, September 4, 2024 Article the full orchestration of a complex materials discovery workﬂow toward novel gain materials for organic solid-state lasing devices. RESULTS Software management Meticulous control over the laboratory’s software ecosystem is imperative to enhance experimental reproducibility, increase transparency, and mitigate produc- tion failures. As such, achieving complete transparency necessitates stringent man- agement of the software state within a laboratory with dependency conﬂicts due to incompatible software versions posing a well-recognized challenge in this regard.36 To address these concerns, the core design of ChemOS 2.0 incorporates an orches- tration fog device that runs the necessary software layers for laboratory operations while keeping each laboratory modular for streamlined integration. To ensure repro- ducibility, robustness, and seamless deployment, the fog orchestration platform is equipped with NixOS, a declarative package-manager-based (Nix) operating sys- tem known for its ability to provide precise control over system state and software A B C D E F Figure 1. Features and capabilities of ChemOS 2.0 (A) Web graphical interface to ease the user interaction. (B) Package to ensure full software reproducibility. (C) Bayesian optimizer platform for experimental planning. (D) DFT workﬂow manager connected to our high-performance computer cluster to orchestrate ab ini\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract full text from a PDF file.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    full_text = \"\"\n",
    "    \n",
    "    for page in doc:\n",
    "        full_text += page.get_text(\"text\") + \"\\n\"\n",
    "    \n",
    "    return full_text\n",
    "\n",
    "def chunk_text(text, chunk_size=1500, overlap=150):\n",
    "    \"\"\"Chunk text into fixed-length segments with overlap.\"\"\"\n",
    "    words = text.split()  # Tokenizing by words (for simplicity)\n",
    "    chunks = []\n",
    "    \n",
    "    start = 0\n",
    "    while start < len(words):\n",
    "        end = start + chunk_size\n",
    "        chunk = \" \".join(words[start:end])\n",
    "        chunks.append(chunk)\n",
    "        start += chunk_size - overlap  # Shift start position with overlap\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Example usage\n",
    "pdf_path = r\"C:\\Users\\Chayan\\OneDrive - University of Toronto\\Desktop\\Winter 25\\M.Eng Project\\Cohere Approach\\pdfs\\1-s2.0-S2590238524001954-main.pdf\"\n",
    "full_text = extract_text_from_pdf(pdf_path)\n",
    "chunks = chunk_text(full_text, chunk_size=1500, overlap=150)\n",
    "\n",
    "# Print the first 2 chunks for preview\n",
    "for i, chunk in enumerate(chunks[:2]):\n",
    "    print(f\"=== Chunk {i+1} ===\\n{chunk[:1500]}\\n\")  # Show first 500 characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_folder= r\"C:\\Users\\Chayan\\OneDrive - University of Toronto\\Desktop\\Winter 25\\M.Eng Project\\Cohere Approach\\pdfs\\Final Papers\"\n",
    "\n",
    "for paper in top_papers:\n",
    "    pdf_path = os.path.join(pdf_folder, f\"{paper['title']}.pdf\")  # Locate PDF by title\n",
    "\n",
    "    if os.path.exists(pdf_path):\n",
    "        full_text = extract_text_from_pdf(pdf_path)  # Extract full text\n",
    "        chunks = chunk_text(full_text, chunk_size=1500, overlap=150)  # Chunk the text\n",
    "\n",
    "        # Store chunks in paper dictionary\n",
    "        paper[\"chunks\"] = chunks\n",
    "    else:\n",
    "        print(f\"PDF not found: {pdf_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rerank_chunks(query, chunks, top_n=3):\n",
    "    \"\"\"Ranks research papers using Cohere Rerank.\"\"\"\n",
    "    rerank_response = co.rerank(model=\"rerank-english-v2.0\", query=query, documents=chunks, top_n=top_n)\n",
    "    reranked_papers = [chunks[result.index] for result in rerank_response.results]\n",
    "    \n",
    "    # Attach rerank scores to papers\n",
    "    for i, paper in enumerate(reranked_papers):\n",
    "        paper[\"rerank_score\"] = rerank_response.results[i].relevance_score\n",
    "    \n",
    "    return reranked_papers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def execute_full_pipeline(query, zotero_metadata, pdf_folder, top_n_papers=3, chunk_size=1500, overlap=150, top_n_chunks=5):\n",
    "    \"\"\"\n",
    "    Execute Phase 1 (Retrieve top papers) and Phase 2 (Extract, chunk, and rerank text).\n",
    "    \n",
    "    Args:\n",
    "        query (str): The query for retrieving relevant papers.\n",
    "        zotero_metadata (dict): Metadata from Zotero containing paper titles and other details.\n",
    "        pdf_folder (str): The folder containing the research PDFs.\n",
    "        top_n_papers (int): Number of top-ranked papers to retrieve.\n",
    "        chunk_size (int): Size of text chunks.\n",
    "        overlap (int): Overlap between chunks.\n",
    "        top_n_chunks (int): Number of top-ranked chunks to return.\n",
    "\n",
    "    Returns:\n",
    "        list: Top-ranked chunks after reranking.\n",
    "    \"\"\"\n",
    "    \n",
    "    # **Phase 1: Retrieve Top Papers**\n",
    "    top_papers = execute_ranking_pipeline(query, zotero_metadata, top_n=top_n_papers)\n",
    "\n",
    "    # **Phase 2: Extract and Chunk Text**\n",
    "    for paper in top_papers:\n",
    "        pdf_path = os.path.join(pdf_folder, f\"{paper['title']}.pdf\")  # Locate PDF by title\n",
    "        \n",
    "        if os.path.exists(pdf_path):\n",
    "            full_text = extract_text_from_pdf(pdf_path)  # Extract text from PDF\n",
    "            chunks = chunk_text(full_text, chunk_size=chunk_size, overlap=overlap)  # Chunking\n",
    "            \n",
    "            # Store chunks in paper dictionary\n",
    "            paper[\"chunks\"] = chunks\n",
    "        else:\n",
    "            print(f\"PDF not found: {pdf_path}\")\n",
    "            paper[\"chunks\"] = []  # Assign empty list if file is missing\n",
    "\n",
    "    # **Prepare Chunks for Reranking**\n",
    "    all_chunks = [{\"title\": paper[\"title\"], \"text\": chunk} for paper in top_papers for chunk in paper[\"chunks\"]]\n",
    "\n",
    "    # **Rerank Chunks**\n",
    "    ranked_chunks = rerank_chunks(query, all_chunks, top_n=top_n_chunks)\n",
    "\n",
    "    return ranked_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Chunk 1 from Autonomous Chemical Experiments Challenges and Perspectives on Establishing a Self Driving Lab ===\n",
      "mixing with other reagents, or even changing the solvent via evaporation and redissolution. Automated experiments where the instruments are linked by stepwise robotic sample transport28,39 require less process optimization for each measurement as the intermediates can simply be purified, and samples can be prepared between successive experiments. In contrast, in-line processes must be optimized so that the initial sample is suitable for all subsequent experiments. Nevertheless, properly optimized in- line processes have the potential to lead to substantial time savings. The advantage of in-line “discovery mode” synthesis is that only very small amounts of material are required for full characterization, which makes it possible to run reactions on a much smaller scale and results in more efficient utilization of both money and materials. However, an important drawback of the in-line approach is that it is limited mainly to characterizing samples dissolved in a single solvent. To address this challenge, we have built a “quasi-in-line” setup, where samples can be dried and redissolved with a different solvent in the collection vials. This can be done after the samples are collected from the HPLC or between multiple rounds of optical characterization in order to measure a sample’s properties in multiple solvents. We have built custom in-line instruments to measure optical properties such as UV−vis absorbance and photoluminescence (PL) spectra, relative PL quantum yield (PLQY),40 photo- degradation rate, and PL lifetime (Figure 4). For the absorption and PL instruments, a charge-coupled device (CCD) spectrometer is coupled to the cell holders for each measurement via a Y-junction optical fiber. In order to estimate the relative PLQY by measuring the absorbed power, the PL instrument has also been equipped with a power meter. In principle, both absorbance and PL spectra can be obtained from the same flow cell. However, we have separated them to maximize the signal-to-noise response for minimal analyte amounts by optimizing the respective cell designs. To measure the PL lifetime of a molecule, the time-resolved PL is recorded using time-correlated single-photon counting (TCSPC)41 with a picosecond pulse laser. The instruments described above are controlled by modules written in Python. All of the measurement parameters such as exposure time for the PL spectrum and excitation intensity and frequency for the PL lifetime measurements can be automatically adapted to ...\n",
      "\n",
      "=== Chunk 2 from Autonomous Chemical Experiments Challenges and Perspectives on Establishing a Self Driving Lab ===\n",
      "develop their software to consider self-driving laboratories. Therefore, sometimes, there is no commercial equipment with an API for comprehensive external control, and programming support is hardly offered. Consequently, the adaptation of an instrument for use in self- driving laboratories often requires a significant time investment to write custom code.32 “Hacking” instruments without a sufficient API introduces potential points of failure. Never- theless, we believe this will change in the future as more laboratories move to automation, but for the moment, vigilance is required when choosing equipment. 4.2. Replacing or Replicating Motor Function The other major type of challenge is replicating or replacing certain actions that are easy for humans because of their fine motor skills and hand-eye coordination. For example, trouble- shooting the electrochemical experiments described above is more suited to human actions because it requires dexterity and coordination between visual inputs and motor response. Electrolyte salts may wick up the working electrode during bulk electrolysis, causing interference in the current response. A human researcher can wipe the electrode gently without interrupting the experiment, but current automated systems cannot. Rather than adapt automated procedures, the three- electrode electrochemical cell must be redesigned to suit automated functionality, as it can increase precision and reproducibility. This is especially true because ASPs struggle to replicate some of these tasks, particularly accurately dispensing small amounts of solids. Dispensing solids automatically is a well- known challenge, especially for solids with very different properties and for amounts less than approximately 20 mg.68,69 The achievement of both accuracy and precision requires substantial calibration and testing. For “discovery mode” synthesis, such an investment is not always feasible as hundreds of solids can require customized settings. Advances are ongoing; however, there is considerable room for improve- ment.70 Accordingly, many self-driving laboratories circumvent that by relying on stock solutions and well-established liquid- handling technologies, allowing the precise down-scaling of procedures. Additionally, the preparation of stock solutions can also be automated with the help of computer vision.71 Accounts of Chemical Research pubs.acs.org/accounts Article https://doi.org/10.1021/acs.accounts.2c00220 Acc. Chem. Res. 2022, 55, 2454−2466...\n",
      "\n",
      "=== Chunk 3 from Autonomous Chemical Experiments Challenges and Perspectives on Establishing a Self Driving Lab ===\n",
      "Autonomous Chemical Experiments: Challenges and Perspectives on Establishing a Self-Driving Lab Martin Seifrid, Robert Pollice, Andrés Aguilar-Granda,† Zamyla Morgan Chan,† Kazuhiro Hotta,† Cher Tian Ser,† Jenya Vestfrid,† Tony C. Wu,† and Alán Aspuru-Guzik* Cite This: Acc. Chem. Res. 2022, 55, 2454−2466 Read Online ACCESS Metrics & More Article Recommendations CONSPECTUS: We must accelerate the pace at which we make technological advancements to address climate change and disease risks worldwide. This swifter pace of discovery requires faster research and development cycles enabled by better integration between hypothesis generation, design, experimentation, and data analysis. Typical research cycles take months to years. However, data-driven automated laboratories, or self-driving laboratories, can significantly accelerate molecular and materials discovery. Recently, substantial advancements have been made in the areas of machine learning and optimization algorithms that have allowed researchers to extract valuable knowledge from multidimensional data sets. Machine learning models can be trained on large data sets from the literature or databases, but their performance can often be hampered by a lack of negative results or metadata. In contrast, data generated by self-driving laboratories can be information-rich, containing precise details of the experimental conditions and metadata. Consequently, much larger amounts of high-quality data are gathered in self-driving laboratories. When placed in open repositories, this data can be used by the research community to reproduce experiments, for more in-depth analysis, or as the basis for further investigation. Accordingly, high-quality open data sets will increase the accessibility and reproducibility of science, which is sorely needed. In this Account, we describe our efforts to build a self-driving lab for the development of a new class of materials: organic semiconductor lasers (OSLs). Since they have only recently been demonstrated, little is known about the molecular and material design rules for thin-film, electrically-pumped OSL devices as compared to other technologies such as organic light-emitting diodes or organic photovoltaics. To realize high-performing OSL materials, we are developing a flexible system for automated synthesis via iterative Suzuki−Miyaura cross-coupling reactions. This automated synthesis platform is directly coupled to the analysis and purification capabilities. Subsequently, th...\n",
      "\n",
      "=== Chunk 4 from Performance metrics to unleash the power of self-driving labs in chemistry and materials science ===\n",
      "Perspective https://doi.org/10.1038/s41467-024-45569-5 Performance metrics to unleash the power of self-driving labs in chemistry and materials science Amanda A. Volk1 & Milad Abolhasani 1 With the rise of self-driving labs (SDLs) and automated experimentation across chemical and materials sciences, there is a considerable challenge in designing the best autonomous lab for a given problem based on published studies alone. Determining what digital and physical features are germane to a speciﬁc study is a critical aspect of SDL design that needs to be approached quanti- tatively. Even when controlling for features such as dimensionality, every experimental space has unique requirements and challenges that inﬂuence the design of the optimal physical platform and algorithm. Metrics such as opti- mization rate are therefore not necessarily indicative of the capabilities of an SDL across different studies. In this perspective, we highlight some of the critical metrics for quantifying performance in SDLs to better guide researchers in implementing the most suitable strategies. We then provide a brief review of the existing literature under the lens of quantiﬁed performance as well as heuristic recommendations for platform and experimental space pairings. Self-driving labs (SDLs) are a rapidly growing ﬁeld that offers incredible potential in improving the rate and scope of research in chemistry and materials science.1 SDLs are novel tools that incor- porate automated experimental workﬂows (physical world) with algorithm-selected experimental parameters (digital world). Such autonomous experimentation tools can navigate complex and exponentially expanding reaction spaces with an efﬁciency unac- hievable through human-led manual experimentation, thereby allowing researchers to explore larger and more complicated experimental systems. At their highest degree of autonomy, the efﬁciency of SDLs can be derived from continuous, automated experimentation, which includes model retraining between each experiment. Such models can navigate and learn complex parameter spaces at a higher efﬁciency than the traditional design of experi- ment (DOE) approaches. These beneﬁts thereby enable the dis- covery and optimization of novel and improved materials and molecules, as well as effective ways to manufacture them at scale. Due to the nascency of the SDL ﬁeld in chemistry and materials science, the wide range of potential reaction space complexities, and the diversity of SDLs appli...\n",
      "\n",
      "=== Chunk 5 from Performance metrics to unleash the power of self-driving labs in chemistry and materials science ===\n",
      "from handling extremely low reaction times, and microﬂuidic reactors typically require solution phase precursors and are constrained to by injection ratios. Precise reporting of the demonstrated and theoretical parameter space along with details of the characterization techniques is critical for commu- nicating the capabilities and limitations of an SDL. Each of the para- meters used in a study should be reported alongside their minimum and maximum bounds and how they are parameterized in the opti- mization algorithms. Furthermore, considerable effort should be made to include qualitative constraints on the accessible list of para- meters that may be used by an SDL. Optimization efﬁciency Finally, and likely most importantly, every SDL study should include a comprehensive evaluation of the overall system performance. Bench- marking with a real-world, experimental platform can be highly chal- lenging, as there is often little data available for direct comparison, and it is typically too costly to conduct replicates with alternative systems or algorithms. Moreover, two seemingly similar experimental systems can feature reaction spaces of differing complexity, resulting in a more challenging optimization for one than the other. Shown in Fig. 4, many aspects of surface response features can inﬂuence the rate of optimi- zation. With these limitations in mind, there are several aspects of a physical platform and the experiment-selection algorithm of SDLs that can serve as reasonable indicators of their performance. First, it is important to specify the optimized feature that was achieved because of the study along with the number of experiments or prior data implemented to reach that outcome. Where relevant, all champion results should be benchmarked with appropriate state-of-the-art Fig. 3 | Effect of noise on optimization efﬁciency. A Surface response plot of a two-dimensional michalewicz surrogate function, (B) median best response and (C) median mean squared error across ten replicates for a simulated optimization of a six-dimensional michalewicz surface with varying degrees of noise indicated by the legend. As the level of noise observed in the surrogate function is increased, the performance of the optimization algorithm decreases while the algorithm model’s uncertainty increases. More precise experimental platforms, therefore, tend to generate higher performing self-driving laboratories. The optimization algorithm uses bagging regression with an exhaustiv...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the challenges of self-driving labs?\"\n",
    "pdf_folder= r\"C:\\Users\\Chayan\\OneDrive - University of Toronto\\Desktop\\Winter 25\\M.Eng Project\\Cohere Approach\\pdfs\\Final Papers\"\n",
    "\n",
    "# Execute full pipeline (Phase 1 + Phase 2)\n",
    "ranked_chunks = execute_full_pipeline(query, zotero_metadata, pdf_folder)\n",
    "\n",
    "# Print the top-ranked chunks\n",
    "for i, chunk in enumerate(ranked_chunks):\n",
    "    print(f\"=== Chunk {i+1} from {chunk['title']} ===\\n{chunk['text'][:2500]}...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Chunk 1 from Research Trend Analysis in the Field of Self Driving Lab Using Network Analysis and Topic Modeling ===\n",
      "Article Not peer-reviewed version Research Trend Analysis in the Field of Self-Driving Lab Using Network Analysis and Topic Modeling Woojun Jung , Insung Hwang , Keuntae Cho * Posted Date: 6 December 2024 doi: 10.20944/preprints202412.0512.v1 Keywords: Self-Driving Lab; SDL; Trend analysis; Network analysis; Topic modeling; Sustainability Preprints.org is a free multidisciplinary platform providing preprint service that is dedicated to making early versions of research outputs permanently available and citable. Preprints posted at Preprints.org appear in Web of Science, Crossref, Google Scholar, Scilit, Europe PMC. Copyright: This open access article is published under a Creative Commons CC BY 4.0 license, which permit the free download, distribution, and reuse, provided that the author and preprint are cited in any reuse. Article Research Trend Analysis in the Field of Self-Driving Lab Using Network Analysis and Topic Modeling Woojun Jung 1, Insung Hwang 1 and Keuntae Cho 2,* 1 Department of Industrial Engineering, Sungkyunkwan University, Suwon 16419, Republic of Korea 2 Department of Systems Management Engineering, Sungkyunkwan University, Suwon 16419, Republic of Korea * Correspondence: ktcho@skku.edu; Tel.: +82-031-290-7602 Abstract: A self-driving lab (SDL) is a system that automates experiment design, data collection, and analysis using robotics and artificial intelligence (AI) technologies, and its significance has grown substantially in recent years. This study analyzes the overall research trends in SDL, examines changes in specific topics, visualizes the relational structure among authors to identify key contributors and extracts major themes from extensive texts to highlight essential research content. To achieve these objectives, trend analysis, network analysis, and topic modeling are conducted on 352 research papers collected from the Web of Science from 2004 to 2023. The results revealed three key findings. First, SDL research has surged since 2019, driven by the pandemic and advancements in AI technologies, reflecting heightened activity in this field. Second, several influential researchers have been identified as central figures in the network, playing pivotal roles in collaboration and information dissemination. Third, SDL research exhibits interdisciplinary convergence, encompassing areas such as material optimization, biological processes, and AI predictive algorithms. This study underscores the growing importance of SDL as a research...\n",
      "\n",
      "=== Chunk 2 from Autonomous chemistry Navigating self-driving labs in chemical and material sciences ===\n",
      "Perspective Autonomous chemistry: Navigating self-driving labs in chemical and material sciences Oliver Bayley,1,2 Elia Savino,1,2 Aidan Slattery,1,2 and Timothy Noe¨ l1,* SUMMARY Self-driving labs (SDLs) have recently emerged as one of the most signiﬁcant technological developments in the chemical and mate- rials sciences and hold the potential to revolutionize the research process. Herein, we discuss the structure of an SDL in terms of the hardware, the coordinator software, and the AI agent and examine how the selection of these elements affects the overall research ca- pabilities. We further look to the application and accessibility of these platforms to better understand their future impact on syn- thetic and materials chemistry. With the rapid rise in the capabilities of these SDLs, and with the increasing democratization of the space, it is crucial to be aware of both the promises and pitfalls this technol- ogy holds. INTRODUCTION In the rapidly evolving landscape of scientiﬁc research, the integration of automa- tion, particularly in the realm of self-driving labs (SDLs), represents a pivotal shift to- ward a more efﬁcient, reproducible, and scalable scientiﬁc method. This approach leverages advanced algorithms (artiﬁcial intelligence [AI] planners), robotics (hard- ware executors), and control software (system coordinators) for the design, execu- tion, and analysis of experiments in an automated fashion. It marks a signiﬁcant de- parture from traditional laboratory practices, promising to accelerate the discovery pace across various ﬁelds of science.1 The potential of SDLs presents the opportu- nity to enable signiﬁcant cost-savings, increased safety and the ability to free up scientists’ time to partake in more exploratory work. Automated science is nothing new, with early attempts at computer-controlled processes having been successfully demonstrated in the mid-20th century with the automation of analytical instruments,2 experimental apparatus,3,4 and due to the sequential and repetitive nature, peptide synthesis.5,6 While the automation in these cases focused on a single component of an experimentalist’s workﬂow, these early endeavors laid the groundwork for the more sophisticated SDL systems we see today. The explosive growth of SDLs in the most recent decade can be attributed to several concurrent technological developments. Firstly, from the hardware front, there has been a signiﬁcant decrease in the costs associated with robotics and high- ...\n",
      "\n",
      "=== Chunk 3 from The future of self-driving laboratories from human in the loop interactive AI to gamification ===\n",
      "The future of self-driving laboratories: from human in the loop interactive AI to gamiﬁcation Holland Hysmith, a Elham Foadian,b Shakti P. Padhy,b Sergei V. Kalinin,bc Rob G. Moore,d Olga S. Ovchinnikovabe and Mahshid Ahmadi *b Recent developments in artiﬁcial intelligence (AI) and machine learning (ML), implemented through self- driving laboratories (SDLs), are rapidly creating unprecedented opportunities for the accelerated discovery and optimization of materials. This paper provides a joint analysis of SDLs from both academic and industry perspectives, highlighting the importance of integrating human intelligence in these systems. It discusses the necessity of careful planning in SDL design across physical, data, and workﬂow dimensions, including instrumental setup, experimental workﬂow, data management, and human–SDL interaction. The signiﬁcance of integrating human input within SDLs, especially as the focus shifts from individual tools and tasks to the creation and management of complex workﬂows, is emphasized. The paper stresses on the crucial role of reward function design in developing forward-looking workﬂows and examines the interplay between hardware evolution, ML application across chemical processes, and the inﬂuence of reward systems in research. Ultimately, the article advocates for a future where SDLs blend human intuition in hypothesis formulation with AI's precision, speed, and data-handling capabilities. I. Materials matter Materials discovery has been driving technological evolution since the dawn of time, long predating the formal establish- ment of materials science in the 1960s.1 Understanding mate- rial properties lies at the cross-section of scientic elds including biology, chemistry, physics, and engineering.2 Mate- rials discovery and optimization comprises the synergy of synthesis and fabrication with property measurements, whether mechanical, chemical, or electrical.1,2 Traditionally, all stages of this process were ideated and implemented by human scien- tists, with automated approaches used only for well-dened and simple operations. The introduction of machine learning (ML) sparked a wave of curiosity among scientists with a new perspective on the scientic method – both in the theory and computation domains, and in real-world applications. The race to create the next best technological breakthrough became not a matter of human tenacity only, but also of utilization of articial intelli- gence (AI).3,4 For many decades, co...\n",
      "\n",
      "=== Chunk 4 from Research Trend Analysis in the Field of Self Driving Lab Using Network Analysis and Topic Modeling ===\n",
      "contribute to the successful implementation and broader adoption of SDL in diverse scientific and industrial contexts. Author Contributions: Conceptualization, W.J., I.H and K.C.; Methodology, W.J.; Software, W.J.; Validation, W.J. and K.C.; Formal analysis, W.J.; Writing—original draft preparation, W.J.; Writing—review and editing, W.J. and K.C.; Supervision, K.C. All authors have read and agreed to the published version of the manuscript. Funding: This research received no external funding. Data Availability Statement: The data used to support the ﬁndings of this research are provided and managed by the South Korean government in the Open Government Data portal (data.go.kr). Conflicts of Interest: The authors declare no conflict of interest. References 1. Garcia Martin, H.; Radivojevic, T.; Zucker, J.; Bouchard, K. E.; Sustarich, J.; Peisert, S.; Arnold, D.; Hillson, N. J.; Babnigg, G.; Martí, J. M.; Mungall, C. J.; Beckham, G. T.; Waldburger, L. M.; Carothers, J. M.; Sundaram, S.; Agarwal, D.; Simmons, B. A.; Backman, T. W. H.; Banerjee, D.; Tanjore, D.; Ramakrishnan, L.; Singh, A. Perspectives for Self-Driving Labs in Synthetic Biology. Current Opinion in Biotechnology. 2022, 79, 102881. 2. Seifrid, M.; Pollice, R.; Aguilar-Granda, A.; Chan, Z. M.; Hotta, K.; Ser, C. T.; Vestfrid, J.; Wu, T. C.; Aspuru- Guzik, A. Autonomous Chemical Experiments: Challenges and Perspectives on Establishing a Self-Driving Lab. Accounts of Chemical Research. 2022, 55, 2454–2466. Preprints.org (www.preprints.org) | NOT PEER-REVIEWED | Posted: 6 December 2024 doi:10.20944/preprints202412.0512.v1 19 3. Abolhasani, M.; Kumacheva, E. The Rise of Self-Driving Labs in Chemical and Materials Sciences. Nature Synthesis. 2023, 2, 483–492. 4. Delgado-Licona, F.; Abolhasani, M. Research Acceleration in Self‐Driving Labs: Technological Roadmap toward Accelerated Materials and Molecular Discovery. Advanced intelligent systems. 2022, 5, 2200331. 5. Da Silva, R.G.L. The advancement of artificial intelligence in biomedical research and health innovation: challenges and opportunities in emerging economies. Global Health. 2024, 20, 44 6. Hysmith, H.; Foadian, E.; Padhy, S. P.; Kalinin, S. V.; Moore, R. G.; Ovchinnikova, O.; Ahmadi, M. The Future of Self-Driving Laboratories: From Human in the Loop Interactive AI to Gamification. Digital discovery. 2024, 3, 621-636. 7. MacLeod, B. P.; Parlane, F. G. L.; Berlinguette, C. P. How to Build an Effective Self-Driving Laboratory. Mrs Bulletin. 2023...\n",
      "\n",
      "=== Chunk 5 from Research Trend Analysis in the Field of Self Driving Lab Using Network Analysis and Topic Modeling ===\n",
      "The integration of ML and innovative approaches to scientific methods has energized both theoretical and computational research domains, in addition to practical applications [6]. Moreover, SDL has significant potential to address critical societal needs such as carbon-neutral processes, food security, sustainable agriculture, clean energy, energy storage, and drug discovery [9]. By leveraging AI and ML algorithms to analyze datasets ranging from small to large, SDL enables researchers to identify patterns and trends, resulting in more effective and efficient R&D processes [10]. Following are some of the areas where SDL is being utilized. Biotechnology: SDL provides a powerful platform for autonomously designing and engineering new biological functions, particularly in synthetic biology and genetic manipulation [11]. For example, SDL has shown promising results in autonomously exploring protein conformational landscapes and advancing biomedical and molecular biology research beyond traditional chemical synthesis methods [12,13]. This enables researchers to investigate the intricate interactions of life systems more efficiently. SDL has also been applied in the development of biochemical response neural networks (CRNNs), which autonomously design neural networks to predict chemical responses and identify experimental pathways [14]. This has proven to be instrumental in understanding and controlling the kinetics of complex chemical reactions. Additionally, advancements such as autonomous implantable devices for neural recording and stimulation in freely moving primates demonstrate SDL’s applications in advanced biomedical research [15]. Chemical Engineering: Traditional computational tools have limitations in accelerating chemical research [16]. SDL addresses this by autonomously exploring multistage chemical pathways, enabling a rapid understanding of complex chemical systems and achieving optimized results [17]. For instance, SDL has been applied to electrocatalyst discovery, utilizing closed-loop approaches for nitrogen reduction reactions to efficiently explore multi-target experimental outcomes [18]. Deep learning-driven SDL systems have also uncovered unknown reaction pathways that significantly contribute to the understanding of complex chemical systems [14]. These advancements extend the boundaries of chemical exploration and enhance global collaboration, thereby fostering the universalization of scientific discovery [19]. Materials Engineering: In m...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is  self-driving labs?\"\n",
    "pdf_folder= r\"C:\\Users\\Chayan\\OneDrive - University of Toronto\\Desktop\\Winter 25\\M.Eng Project\\Cohere Approach\\pdfs\\Final Papers\"\n",
    "\n",
    "# Execute Retrieval full pipeline (Phase 1 + Phase 2)\n",
    "ranked_chunks = execute_full_pipeline(query, zotero_metadata, pdf_folder)\n",
    "\n",
    "# Print the top-ranked chunks\n",
    "for i, chunk in enumerate(ranked_chunks):\n",
    "    print(f\"=== Chunk {i+1} from {chunk['title']} ===\\n{chunk['text'][:2500]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Responses from the retrieved context chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere  # Cohere API client\n",
    "\n",
    "# Initialize Cohere client (replace with your API key)\n",
    "co = cohere.Client(api_key=env.cohere_key)\n",
    "\n",
    "def response_to_chunks(query, ranked_chunks, model=\"command-r-plus-08-2024\"):\n",
    "    \"\"\"\n",
    "    Generates an LLM response based on retrieved and reranked research chunks.\n",
    "\n",
    "    Args:\n",
    "        query (str): The user query.\n",
    "        ranked_chunks (list): List of top-ranked text chunks.\n",
    "        model (str): Cohere model name for chat generation.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (Generated response text, citations)\n",
    "    \"\"\"\n",
    "    # Execute Retrieval full pipeline (Phase 1 + Phase 2)\n",
    "    ranked_chunks = execute_full_pipeline(query, zotero_metadata, pdf_folder)\n",
    "    \n",
    "    # **Fix: Ensure `data` is a String (Not a Dictionary)**\n",
    "    documents = [{\"data\": f\"{chunk['title']}: {chunk['text']}\"} for chunk in ranked_chunks]\n",
    "\n",
    "    # **System Prompt for Context Awareness**\n",
    "    system_prompt = (\n",
    "        \"You are an AI research assistant specializing in self-driving labs and automation. \"\n",
    "        \"Use the provided research excerpts to answer queries accurately. \"\n",
    "        \"Avoid speculation—if an answer is not found in the documents, state it explicitly.\"\n",
    "    )\n",
    "\n",
    "    # **Format the Query**\n",
    "    user_message = (\n",
    "        f\"Format your response as follows:\\n\"\n",
    "        \"**Query:** {query}\\n\"\n",
    "        \"- **Summary:** (Concise response)\\n\"\n",
    "        \"- **Key points:** (List the most important points)\\n\"\n",
    "        \"- **Sources:** (List titles of the relevant research excerpts)\"\n",
    "        \n",
    "    )\n",
    "\n",
    "    # **Call Cohere's `chat()` API Correctly**\n",
    "    response = co.chat(\n",
    "        model=model,\n",
    "        message=user_message,  # Fix: Using `message` instead of `messages`\n",
    "        documents=documents,  # Pass the context as `documents`\n",
    "        preamble=system_prompt  # Fix: Use `preamble` for system instructions\n",
    "    )\n",
    "\n",
    "    return response.text, response.citations  # Extract response text & citations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "document id=doc_0 is too long and may provide bad results, please chunk your documents to 300 words or less, document id=doc_1 is too long and may provide bad results, please chunk your documents to 300 words or less, document id=doc_2 is too long and may provide bad results, please chunk your documents to 300 words or less, document id=doc_3 is too long and may provide bad results, please chunk your documents to 300 words or less, document id=doc_4 is too long and may provide bad results, please chunk your documents to 300 words or less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINAL RESPONSE FROM LLM ===\n",
      "**Query:** What are the key challenges in establishing a self-driving lab?\n",
      "- **Summary:** Self-driving labs are a rapidly growing field that offers incredible potential in improving the rate and scope of research in chemistry and materials science. However, there are several challenges in establishing a self-driving lab, which can be split into cognitive and motor function.\n",
      "- **Key Challenges:**\n",
      "  - **Cognitive Challenges:**\n",
      "    - Replacing human cognitive processes with ML algorithms in the \"real world\" of chemistry.\n",
      "    - Encountering unexpected or difficult-to-predict results.\n",
      "    - Automating instruments designed for human use.\n",
      "    - Optimization with constraints or unexpected outcomes.\n",
      "    - Software control and integration, as few instrument manufacturers design their products with self-driving labs in mind.\n",
      "  - **Motor Function Challenges:**\n",
      "    - Replacing or replicating certain actions that are easy for humans due to their fine motor skills and hand-eye coordination.\n",
      "    - Handling heterogeneous systems, such as dispensing solids or performing extractions.\n",
      "    - Adapting experimental procedures designed for human experimenters to automated systems.\n",
      "    - Troubleshooting electrochemical experiments, which require dexterity and coordination between visual inputs and motor response.\n",
      "- **Sources:** Autonomous Chemical Experiments Challenges and Perspectives on Establishing a Self Driving Lab, Performance metrics to unleash the power of self-driving labs in chemistry and materials science\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the challenges of self-driving labs?\"\n",
    "\n",
    "# Execute full pipeline (Phase 1 + Phase 2 + Phase 3)\n",
    "final_response, citation = response_to_chunks(query, ranked_chunks)\n",
    "\n",
    "# Print the response from the model\n",
    "print(\"=== FINAL RESPONSE FROM LLM ===\")\n",
    "print(final_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "document id=doc_0 is too long and may provide bad results, please chunk your documents to 300 words or less, document id=doc_1 is too long and may provide bad results, please chunk your documents to 300 words or less, document id=doc_2 is too long and may provide bad results, please chunk your documents to 300 words or less, document id=doc_3 is too long and may provide bad results, please chunk your documents to 300 words or less, document id=doc_4 is too long and may provide bad results, please chunk your documents to 300 words or less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINAL RESPONSE FROM LLM ===\n",
      "**Query:** What are the key findings of the research trend analysis in the field of self-driving labs?\n",
      "- **Summary:** The research trend analysis in the field of self-driving labs (SDLs) reveals three key findings: a surge in SDL research since 2019, the identification of influential researchers as central figures in the network, and the interdisciplinary convergence of SDL research.\n",
      "- **Key points:**\n",
      "   - SDL research has experienced a significant increase since 2019, driven by the pandemic and advancements in AI technologies.\n",
      "   - Several influential researchers have been identified as pivotal contributors to the network, playing essential roles in collaboration and information dissemination.\n",
      "   - SDL research exhibits interdisciplinary convergence, encompassing areas such as material optimization, biological processes, and AI predictive algorithms.\n",
      "- **Sources:**\n",
      "   - Research Trend Analysis in the Field of Self Driving Lab Using Network Analysis and Topic Modeling\n",
      "   - Autonomous Chemistry Navigating Self-Driving Labs in Chemical and Material Sciences: Perspective\n",
      "   - The Future of Self-Driving Laboratories from Human in the Loop Interactive AI to Gamification\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the research trends in the field of self driving labs\"\n",
    "\n",
    "# Execute full pipeline (Phase 1 + Phase 2 + Phase 3)\n",
    "final_response, citation = response_to_chunks(query, ranked_chunks)\n",
    "\n",
    "# Print the response from the model\n",
    "print(\"=== FINAL RESPONSE FROM LLM ===\")\n",
    "print(final_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "document id=doc_0 is too long and may provide bad results, please chunk your documents to 300 words or less, document id=doc_1 is too long and may provide bad results, please chunk your documents to 300 words or less, document id=doc_2 is too long and may provide bad results, please chunk your documents to 300 words or less, document id=doc_3 is too long and may provide bad results, please chunk your documents to 300 words or less, document id=doc_4 is too long and may provide bad results, please chunk your documents to 300 words or less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINAL RESPONSE FROM LLM ===\n",
      "**Query:** What are the key findings of the research trend analysis in the field of self-driving labs?\n",
      "- **Summary:** The research trend analysis in the field of self-driving labs (SDLs) reveals three key findings: a surge in SDL research since 2019, the identification of influential researchers as central figures in the network, and the interdisciplinary convergence of SDL research.\n",
      "- **Key points:**\n",
      "   - SDL research has experienced a significant increase since 2019, driven by the pandemic and advancements in AI technologies.\n",
      "   - Several influential researchers have been identified as pivotal contributors, playing essential roles in collaboration and information dissemination.\n",
      "   - SDL research demonstrates interdisciplinary convergence, encompassing areas such as material optimization, biological processes, and AI predictive algorithms.\n",
      "- **Sources:**\n",
      "   - Research Trend Analysis in the Field of Self Driving Lab Using Network Analysis and Topic Modeling\n",
      "   - Autonomous chemistry Navigating self-driving labs in chemical and material sciences: Perspective\n",
      "   - The future of self-driving laboratories from human in the loop interactive AI to gamification\n",
      "   - Research Trend Analysis in the Field of Self Driving Lab Using Network Analysis and Topic Modeling: contribute to the successful implementation and broader adoption of SDL in diverse scientific and industrial contexts.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the future  of self driving labs\"\n",
    "\n",
    "# Execute full pipeline (Phase 1 + Phase 2 + Phase 3)\n",
    "final_response, citation = response_to_chunks(query, ranked_chunks)\n",
    "\n",
    "# Print the response from the model\n",
    "print(\"=== FINAL RESPONSE FROM LLM ===\")\n",
    "print(final_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
